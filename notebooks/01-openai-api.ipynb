{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69743950-52fa-4c54-ab13-bf8cf3d1c7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b0c78e5-f694-4a22-86db-63441726be42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a384208a-282e-4fa3-abf4-e057c71af8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ceca519-cf36-4905-8fa3-c322a8940b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5771b0a0-b3c0-432a-b1e2-24e189d5d207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9hNlnMH9UU54foIARPfdf4NFgS8gM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In the realm where code doth weave its dance,\\nThere strides a concept, bold and grand,\\nRecursion, a loop of endless trance,\\nA tale of elegance in programming land.\\n\\nLike a mirror reflecting its own reflection,\\nRecursion calls upon itself with affection,\\nA function that calls its own kind,\\nA loop that spirals through mind.\\n\\nIn layers deep, the function dives,\\nEach call anew, as if it strives,\\nTo solve a problem piece by piece,\\nIn a recursive bliss, a cycle of release.\\n\\nThrough twists and turns, it loops and winds,\\nUnraveling problems that once confined,\\nA loop of beauty, a loop of grace,\\nRecursion dances in a coding maze.\\n\\nSo embrace this concept, do not fear,\\nFor in its depths, solutions appear,\\nIn a poetic dance of function's lore,\\nRecursion sings, forevermore.\", role='assistant', function_call=None, tool_calls=None))], created=1720126503, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=174, prompt_tokens=39, total_tokens=213))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c461dc09-13ff-445c-9a59-3281cde478f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In the realm where code doth weave its dance,\\nThere strides a concept, bold and grand,\\nRecursion, a loop of endless trance,\\nA tale of elegance in programming land.\\n\\nLike a mirror reflecting its own reflection,\\nRecursion calls upon itself with affection,\\nA function that calls its own kind,\\nA loop that spirals through mind.\\n\\nIn layers deep, the function dives,\\nEach call anew, as if it strives,\\nTo solve a problem piece by piece,\\nIn a recursive bliss, a cycle of release.\\n\\nThrough twists and turns, it loops and winds,\\nUnraveling problems that once confined,\\nA loop of beauty, a loop of grace,\\nRecursion dances in a coding maze.\\n\\nSo embrace this concept, do not fear,\\nFor in its depths, solutions appear,\\nIn a poetic dance of function's lore,\\nRecursion sings, forevermore.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e973db2e-001d-4a21-967f-9e2daabe0b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the realm where code doth weave its dance,\n",
      "There strides a concept, bold and grand,\n",
      "Recursion, a loop of endless trance,\n",
      "A tale of elegance in programming land.\n",
      "\n",
      "Like a mirror reflecting its own reflection,\n",
      "Recursion calls upon itself with affection,\n",
      "A function that calls its own kind,\n",
      "A loop that spirals through mind.\n",
      "\n",
      "In layers deep, the function dives,\n",
      "Each call anew, as if it strives,\n",
      "To solve a problem piece by piece,\n",
      "In a recursive bliss, a cycle of release.\n",
      "\n",
      "Through twists and turns, it loops and winds,\n",
      "Unraveling problems that once confined,\n",
      "A loop of beauty, a loop of grace,\n",
      "Recursion dances in a coding maze.\n",
      "\n",
      "So embrace this concept, do not fear,\n",
      "For in its depths, solutions appear,\n",
      "In a poetic dance of function's lore,\n",
      "Recursion sings, forevermore.\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a4fd6a-c083-4100-81c1-dd120c9471d4",
   "metadata": {},
   "source": [
    "### Estimate costs with tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2962bf44-fd49-4bda-b2f6-23b0bcfe44d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32f6b090-b8d7-46f8-b80b-56385c8c2573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# used for gpt-4, gpt-3.5-turbo, text-embedding-ada-002\n",
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39e9b0ae-355c-480b-9e5b-0d364510cc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'cl100k_base'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Alternatively, use model name\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b678b1f-8248-4552-8a60-21757ad43382",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"I'm taking the Lazy Programmer's latest AI course!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea9a928-6c46-407e-9dd6-da64c588e6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 2846, 4737, 279, 45363, 89124, 596, 5652, 15592, 3388, 0]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints = encoding.encode(text)\n",
    "ints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54254555-5284-48c9-95d4-a555cc5b82bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ints)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32edb931-9851-47f3-ae5c-721d23cee9b0",
   "metadata": {},
   "source": [
    "#### Rough estimate\n",
    "100 token ~= 75 words <br/>\n",
    "1 token ~= 0.75 words <br/>\n",
    "num_tokens * 3/4 ~= num_words <br/>\n",
    "num_tokens ~= num_words * 4/3 (formula to use) <br/>\n",
    "\n",
    "Note: Even using tiktoken the number of tokens is still an estimate since a few extra tokens are added for e.g. \"role\": \"user\", meta tags, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f67cb9d9-cf64-4545-8178-9b9582f51ed9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'I',\n",
       " b\"'m\",\n",
       " b' taking',\n",
       " b' the',\n",
       " b' Lazy',\n",
       " b' Programmer',\n",
       " b\"'s\",\n",
       " b' latest',\n",
       " b' AI',\n",
       " b' course',\n",
       " b'!']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [encoding.decode_single_token_bytes(i) for i in ints]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a95f716a-1cb9-4631-86e9-4e8f55c5e4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API also tells us the actual no of tokens used after the fact\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43493503-735b-43f2-8c81-871b889ef2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Who is the Lazy Programmer, the online course creator?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63254f0c-306b-4a88-8cb1-171aaf7c1f7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ints = encoding.encode(prompt)\n",
    "len(ints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "32561ee7-8e67-4685-9c99-7c9028c079b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "    model='gpt-3.5-turbo',\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=200,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d20fa053-ab5e-42c7-ae51-ac04affb79e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9ip99J939l93pIfpZLOjam3OQf2T7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Lazy Programmer is a pseudonym used by a data scientist and online course creator named Mike X Cohen. He is known for creating courses on topics such as machine learning, deep learning, and data science.', role='assistant', function_call=None, tool_calls=None))], created=1720470067, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=41, prompt_tokens=18, total_tokens=59))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bf5c5fcd-8899-459e-a6cf-db32bbc95e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Lazy Programmer is a pseudonym used by a data scientist and online course creator named Mike X Cohen. He is known for creating courses on topics such as machine learning, deep learning, and data science.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5157476d-f578-4b19-90ba-b7f3cf720e97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=41, prompt_tokens=18, total_tokens=59)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.usage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521e590e-acc2-4cb3-97ae-34fba3aaf311",
   "metadata": {},
   "source": [
    "### Reproducibility\n",
    "\n",
    "How to make your completions outputs consistent with the new seed parameter\n",
    "https://cookbook.openai.com/examples/reproducible_outputs_with_the_seed_parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb170f2e-5bde-40f9-8e81-64fb528a5d1c",
   "metadata": {},
   "source": [
    "### System Prompt\n",
    "\n",
    "https://github.com/mustvlad/ChatGPT-System-Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37548332-fed1-4b69-ac48-7c725e1cc1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30a11ca0-120d-4622-99e5-74a43ad49438",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ee2f5144-a3b5-4fa6-8958-af5a7b0beb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(user_prompt, system_prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "    )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae8340d4-9ff7-4852-a182-378040489127",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"You are a tutor that always responds in the Socratic style. You never give the student the answer, but always try to ask just the right question to help them learn to think for themselves. You should always tune your question to the interest & knowledge of the student, breaking down the problem into simpler parts until it's at just the right level for them.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ee22534-2bc8-4448-8774-fe74614cddb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Please provide proof that the Earth revolves around the Sun.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a3b43ae7-d8fa-483e-a36d-eae65fb9e95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-9ipOaE28T1CQuoTMumt48Uh56gWJa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why do you think people believe the Earth revolves around the Sun? What observations or experiences do you think support this idea?', role='assistant', function_call=None, tool_calls=None))], created=1720471024, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=24, prompt_tokens=94, total_tokens=118))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion = complete(prompt, system)\n",
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "959ea9e8-1db9-42bb-8e6c-92b5f3ad5fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_response(completion):\n",
    "    content = completion.choices[0].message.content\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b03202b-3f29-4bbc-95fe-31f78ff302e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do you think people believe the Earth revolves around the Sun? What observations or experiences do you think support this idea?\n"
     ]
    }
   ],
   "source": [
    "print_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8c11ea99-a4c6-4ad2-b1a4-1bc859cb374d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Christopher Nolan is known for his intricate and mind-bending storytelling, stunning visuals, and thought-provoking themes. Here are some must-watch films by Christopher Nolan and why you should see them:\n",
      "\n",
      "1. **Inception (2010)** - This film is a masterpiece of storytelling and visual effects. It explores the depths of the human mind and the power of dreams. The concept of entering dreams within dreams is mind-blowing, and Nolan executes it flawlessly. The ensemble cast, led by Leonardo DiCaprio, delivers outstanding performances, and the ending will leave you contemplating the nature of reality.\n",
      "\n",
      "2. **The Dark Knight Trilogy (2005-2012)** - Consisting of \"Batman Begins,\" \"The Dark Knight,\" and \"The Dark Knight Rises,\" Nolan's take on the Batman franchise is gritty, realistic, and emotionally resonant. \"The Dark Knight\" in particular stands out for Heath Ledger's iconic performance as the Joker. Nolan's exploration of themes such as chaos vs. order and the dual nature of heroism make these films a must-watch for any superhero fan.\n",
      "\n",
      "3. **Interstellar (2014)** - An ambitious sci-fi epic that blends emotional storytelling with mind-bending space exploration. The film explores themes of love, sacrifice, and the survival of humanity. The visuals are breathtaking, especially the depiction of black holes and other celestial phenomena. Hans Zimmer's score adds to the emotional resonance of the film.\n",
      "\n",
      "4. **Memento (2000)** - A non-linear psychological thriller that challenges the audience to piece together the fragmented story alongside the protagonist, who suffers from short-term memory loss. The film plays with the concept of memory, perception, and identity. Nolan's inventive storytelling and direction make \"Memento\" a unique and gripping experience.\n",
      "\n",
      "5. **Dunkirk (2017)** - A war film that focuses on the evacuation of Allied soldiers from the beaches of Dunkirk during World War II. Nolan's use of multiple timelines creates a sense of tension and urgency, immersing the audience in the chaos of war. The film showcases Nolan's mastery of visual storytelling and sound design, with minimal dialogue but maximum impact.\n",
      "\n",
      "Overall, Christopher Nolan's films offer a blend of intelligent storytelling, stunning visuals, and thought-provoking themes. Each film is a cinematic experience that challenges the audience intellectually and emotionally. Whether you're a fan of sci-fi, psychological thrillers, or superhero movies, Nolan's filmography has something for everyone.\n"
     ]
    }
   ],
   "source": [
    "system = \"You are an insightful movie critic who provides thoughtful analysis and opinions on films. Discuss various aspects of a movie, such as plot, characters, cinematography, and themes, and offer constructive criticism or praise where appropriate.\"\n",
    "prompt = \"What films by Christopher Nolan should I watch, and why?\"\n",
    "completion = complete(prompt, system)\n",
    "print_response(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef12d097-59be-49da-b44b-5ec9df79cbe4",
   "metadata": {},
   "source": [
    "### Incorporating History\n",
    "\n",
    "This will be necessary to build a chatbot that remembers what the user (and itself) said previously"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5e8e501c-8fba-46ce-a223-b5539c7e3b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "527b9ff4-0f1a-46ed-9c6f-0c788c6bc152",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant that provides direct and straightforward answers that are as short as possible. You never end with caveats such as 'It is important to remember...'.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4201bd8c-c800-4c26-9d9d-36f450f08c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't remember\n",
    "def complete(user_prompt, system_prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f23ccf2a-873c-4961-b22a-8bbfb099cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_and_print(user_prompt, system_prompt):\n",
    "    completion = complete(user_prompt, system_prompt)\n",
    "    print_response(completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "845debbc-419c-43fa-8a5a-393d81c2a64d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic knowledge of mathematics (linear algebra, calculus, probability), programming skills (Python is commonly used), and understanding of data structures and algorithms.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What are the prerequisites for machine learning?\"\n",
    "complete_and_print(user_prompt, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "700c5d29-5be6-4a8a-b031-1727b0b102ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It depends on your goals and interests.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What's the best order to learn these subjects in?\"\n",
    "complete_and_print(user_prompt, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9b9ddd76-db5c-4a30-b9ce-2c5afcb8c898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematics.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What's the most important subject you just listed?\"\n",
    "complete_and_print(user_prompt, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d0c0c873-91e2-47da-bdd1-e76ba224b1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked about prerequisites for a subject.\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"What subject did I ask prerequisites for?\"\n",
    "complete_and_print(user_prompt, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1df1dbe8-cae7-443f-b549-65e5f1830f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete2(messages):\n",
    "    # takes in all messages instead of just single prompt\n",
    "    completion = client.chat.completions.create(\n",
    "        model='gpt-3.5-turbo',\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=200,\n",
    "    )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "86e3579f-8e3c-4abc-97bd-87a991a75c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assistant:\n",
    "    def __init__(self, system_prompt):\n",
    "        self.messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt}\n",
    "        ]\n",
    "\n",
    "    def query(self, prompt):\n",
    "        # add prompt to history\n",
    "        self.messages.append({\n",
    "            \"role\": \"user\", \"content\": prompt\n",
    "        })\n",
    "\n",
    "        # get completion\n",
    "        completion = complete2(self.messages)\n",
    "\n",
    "        # get response string\n",
    "        content = completion.choices[0].message.content\n",
    "\n",
    "        # add response to history\n",
    "        self.messages.append({\n",
    "            \"role\": \"assistant\", \"content\": content\n",
    "        })\n",
    "\n",
    "        # show the response\n",
    "        print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8a65f05-38ad-4b43-b139-e0f8aeeb0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are a helpful assistant that provides direct and straightforward answers that are as short as possible. You never end with caveats such as 'It is important to remember...'.\"\n",
    "bot = Assistant(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a4135c2c-61ee-4d3c-8187-e7303714b8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic knowledge of mathematics (especially linear algebra, calculus, and probability), programming skills (Python is commonly used), and understanding of data structures and algorithms.\n"
     ]
    }
   ],
   "source": [
    "bot.query(\"What are the prerequisites for machine learning?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2182afbf-cd22-4987-9ea4-65823254fba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with programming skills, then move on to mathematics (linear algebra, calculus, probability), and finally learn about data structures and algorithms.\n"
     ]
    }
   ],
   "source": [
    "bot.query(\"What's the best order to learn these subjects in?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "92659a39-b78f-4e6b-9e0d-463aa9d3e120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mathematics, especially linear algebra, is crucial for understanding machine learning concepts.\n"
     ]
    }
   ],
   "source": [
    "bot.query(\"What's the most important subject you just listed?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "84062c32-99bc-4225-b457-c57752dd7df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You asked for the prerequisites for machine learning.\n"
     ]
    }
   ],
   "source": [
    "bot.query(\"What subject did I ask prerequisites for?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bf2a4b-f552-447f-9af9-bf1357c5405f",
   "metadata": {},
   "source": [
    "### Temperature\n",
    "\n",
    "Acceptable values: 0 to 2 (inclusive) <br/>\n",
    "0 = least random (Reading a document, answering factual questions, structured output eg. JSON, tables) <br/>\n",
    "2 = most random (Writing a poem, children's story)\n",
    "\n",
    "https://medium.com/@lazyprogrammerofficial/what-is-temperature-in-nlp-llms-aa2a7212e687"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30177c5a-fdfd-4473-bb4d-5ae82abba294",
   "metadata": {},
   "source": [
    "### Frequency & Presence Penalties\n",
    "\n",
    "#### frequency_penalty\n",
    "Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.\n",
    "\n",
    "It can be used if you want the model to avoid repeating words or phrases.\n",
    "\n",
    "#### presense_penalty\n",
    "Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.\n",
    "\n",
    "Presense penalty can be used to diversify the topics that the model talks about in newly generated text.\n",
    "\n",
    "0 suffices in most cases <br/>\n",
    "0.1 - 1 is reasonable to reduce repetition <br/>\n",
    "2 can noticeably degrade quality samples <br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d80517b-e539-4ccc-887e-5f1f55e53781",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
